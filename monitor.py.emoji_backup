import psutil
import time
import os
import polars as pl
from datetime import datetime
from typing import Dict, List
import threading
import json

class SystemMonitor:
    """Monitor del sistema en tiempo real"""
    
    def __init__(self):
        try:
            self.process = psutil.Process()
        except:
            self.process = None
        self.start_time = time.time()
        self.stats = {
            'files_processed': 0,
            'total_records': 0,
            'successful_matches': 0,
            'errors': 0,
            'avg_processing_time': 0,
            'peak_memory_mb': 0
        }
        self.is_monitoring = False
        
    def start_monitoring(self, interval: float = 1.0):
        """Inicia el monitoreo en background"""
        self.is_monitoring = True
        
        def monitor_loop():
            while self.is_monitoring:
                self._update_stats()
                self._display_stats()
                time.sleep(interval)
        
        monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        monitor_thread.start()
        print("ğŸ” Monitor iniciado - presiona Ctrl+C para detener")
    
    def stop_monitoring(self):
        """Detiene el monitoreo"""
        self.is_monitoring = False
        print("\nğŸ›‘ Monitor detenido")
    
    def _update_stats(self):
        """Actualiza estadÃ­sticas del sistema"""
        current_stats = {'memory_mb': 0, 'cpu_percent': 0, 'uptime_minutes': 0}
        
        # Memoria actual
        if self.process:
            try:
                memory_mb = self.process.memory_info().rss / 1024 / 1024
                if memory_mb > self.stats['peak_memory_mb']:
                    self.stats['peak_memory_mb'] = memory_mb
                current_stats['memory_mb'] = memory_mb
                
                # CPU actual
                current_stats['cpu_percent'] = self.process.cpu_percent()
            except:
                pass
        
        # Tiempo de actividad
        current_stats['uptime_minutes'] = (time.time() - self.start_time) / 60
        
        # Archivos CSV en directorio
        csv_files = [f for f in os.listdir('.') if f.endswith('_processed.csv')]
        self.stats['files_processed'] = len(csv_files)
        
        return current_stats
    
    def _display_stats(self):
        """Muestra estadÃ­sticas en consola"""
        current = self._update_stats()
        
        # Limpiar pantalla (Windows)
        os.system('cls' if os.name == 'nt' else 'clear')
        
        print("=" * 60)
        print("ğŸ” MONITOR CSV-FIREBIRD AUTOMATION")
        print("=" * 60)
        print(f"â° Tiempo activo: {current['uptime_minutes']:.1f} minutos")
        print(f"ğŸ§  Memoria: {current['memory_mb']:.1f} MB (pico: {self.stats['peak_memory_mb']:.1f} MB)")
        print(f"âš¡ CPU: {current['cpu_percent']:.1f}%")
        print()
        print("ğŸ“Š ESTADÃSTICAS DE PROCESAMIENTO:")
        print(f"   ğŸ“ Archivos procesados: {self.stats['files_processed']}")
        print(f"   ğŸ“ Registros totales: {self.stats['total_records']:,}")
        print(f"   âœ… Matches exitosos: {self.stats['successful_matches']:,}")
        print(f"   âŒ Errores: {self.stats['errors']}")
        if self.stats['files_processed'] > 0:
            print(f"   â±ï¸ Tiempo promedio: {self.stats['avg_processing_time']:.1f}s")
        print()
        print("ğŸ”„ Actualizando cada segundo... (Ctrl+C para salir)")

    def log_processing_result(self, result: Dict):
        """Registra resultado de procesamiento"""
        self.stats['total_records'] += result.get('processed_count', 0)
        self.stats['successful_matches'] += result.get('matched_count', 0)
        self.stats['errors'] += len(result.get('errors', []))
        
        # Calcular tiempo promedio
        if result.get('execution_time'):
            current_avg = self.stats['avg_processing_time']
            files_count = self.stats['files_processed']
            new_avg = (current_avg * files_count + result['execution_time']) / (files_count + 1)
            self.stats['avg_processing_time'] = new_avg

class CSVAnalyzer:
    """Analizador avanzado de archivos CSV"""
    
    def __init__(self):
        self.analysis_cache = {}
    
    def analyze_csv(self, file_path: str) -> Dict:
        """Analiza un archivo CSV completamente"""
        if file_path in self.analysis_cache:
            return self.analysis_cache[file_path]
        
        print(f"ğŸ” Analizando: {os.path.basename(file_path)}")
        
        start_time = time.time()
        
        # InformaciÃ³n bÃ¡sica del archivo
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        
        try:
            # AnÃ¡lisis con Polars (mÃ¡s rÃ¡pido)
            sample_df = pl.read_csv(
                file_path,
                has_header=False,
                n_rows=50,  # Solo primeras 50 filas para anÃ¡lisis
                dtypes=str,
                ignore_errors=True
            )
            
            # AnÃ¡lisis completo para archivos pequeÃ±os
            if file_size_mb < 10:
                full_df = pl.read_csv(file_path, has_header=False, dtypes=str, ignore_errors=True)
                total_rows = full_df.height
                total_cols = full_df.width
            else:
                # EstimaciÃ³n para archivos grandes
                lines_sample = sample_df.height
                estimated_total = int((file_size_mb * 1024 * 1024) / (lines_sample * 100))  # EstimaciÃ³n
                total_rows = estimated_total
                total_cols = sample_df.width
            
            analysis = {
                'file_path': file_path,
                'file_size_mb': file_size_mb,
                'total_rows': total_rows,
                'total_cols': total_cols,
                'analysis_time': time.time() - start_time,
                'format_issues': self._check_format_issues(sample_df),
                'propuesta_analysis': self._analyze_propuesta_column(sample_df),
                'data_quality': self._assess_data_quality(sample_df),
                'performance_recommendation': self._get_performance_recommendation(file_size_mb, total_rows),
                'processing_estimate': self._estimate_processing_time(total_rows)
            }
            
            self.analysis_cache[file_path] = analysis
            return analysis
            
        except Exception as e:
            return {
                'file_path': file_path,
                'error': str(e),
                'file_size_mb': file_size_mb,
                'analysis_time': time.time() - start_time
            }
    
    def _check_format_issues(self, df: pl.DataFrame) -> List[str]:
        """Detecta problemas de formato en el CSV"""
        issues = []
        
        # Verificar inconsistencias en nÃºmero de columnas
        if df.height > 10:
            col_counts = []
            for i in range(min(20, df.height)):
                row_data = df.row(i)
                col_counts.append(len([x for x in row_data if x is not None]))
            
            if len(set(col_counts)) > 2:
                issues.append("âš ï¸ Inconsistencia en nÃºmero de columnas por fila")
        
        # Verificar caracteres especiales problemÃ¡ticos
        if df.width > 1:
            sample_col_b = df.get_column("column_1")[:10]
            for val in sample_col_b:
                if val and any(char in str(val) for char in ['"', '\n', '\r']):
                    issues.append("âš ï¸ Caracteres especiales detectados en columna B")
                    break
        
        return issues
    
    def _analyze_propuesta_column(self, df: pl.DataFrame) -> Dict:
        """Analiza especÃ­ficamente la columna de propuestas (columna B)"""
        if df.width < 2:
            return {'error': 'No se encontrÃ³ columna B'}
        
        propuesta_col = df.get_column("column_1")
        
        # Contar propuestas vÃ¡lidas desde fila 11
        valid_propuestas = 0
        empty_propuestas = 0
        sample_propuestas = []
        
        start_idx = min(10, df.height - 1)  # Fila 11 (Ã­ndice 10)
        
        for i in range(start_idx, min(start_idx + 20, df.height)):
            if i < len(propuesta_col):
                val = propuesta_col[i]
                if val and str(val).strip():
                    valid_propuestas += 1
                    if len(sample_propuestas) < 5:
                        sample_propuestas.append(str(val).strip())
                else:
                    empty_propuestas += 1
        
        return {
            'valid_propuestas_sample': valid_propuestas,
            'empty_propuestas_sample': empty_propuestas,
            'sample_values': sample_propuestas,
            'data_starts_at_row': 11,
            'propuesta_column': 'B (column_1)'
        }
    
    def _assess_data_quality(self, df: pl.DataFrame) -> Dict:
        """EvalÃºa la calidad general de los datos"""
        total_cells = df.height * df.width
        empty_cells = 0
        
        # Contar celdas vacÃ­as en muestra
        for i in range(min(20, df.height)):
            row_data = df.row(i)
            empty_cells += sum(1 for x in row_data if x is None or str(x).strip() == '')
        
        empty_percentage = (empty_cells / (20 * df.width)) * 100 if df.width > 0 else 0
        
        quality_score = max(0, 100 - empty_percentage)
        
        return {
            'empty_cells_percentage': empty_percentage,
            'quality_score': quality_score,
            'quality_level': (
                'Excelente' if quality_score >= 90 else
                'Buena' if quality_score >= 70 else
                'Regular' if quality_score >= 50 else
                'Necesita revisiÃ³n'
            )
        }
    
    def _get_performance_recommendation(self, file_size_mb: float, total_rows: int) -> Dict:
        """Sugiere configuraciÃ³n Ã³ptima para el procesamiento"""
        if file_size_mb > 100:
            return {
                'strategy': 'streaming',
                'chunk_size': 5000,
                'memory_estimate': f"{file_size_mb * 0.3:.1f} MB",
                'recommendation': 'Usar procesamiento streaming para archivo grande'
            }
        elif file_size_mb > 10:
            return {
                'strategy': 'chunked',
                'chunk_size': 10000,
                'memory_estimate': f"{file_size_mb * 0.8:.1f} MB",
                'recommendation': 'Procesamiento por lotes recomendado'
            }
        else:
            return {
                'strategy': 'standard',
                'chunk_size': total_rows,
                'memory_estimate': f"{file_size_mb * 1.5:.1f} MB",
                'recommendation': 'Procesamiento estÃ¡ndar en memoria'
            }
    
    def _estimate_processing_time(self, total_rows: int) -> Dict:
        """Estima tiempo de procesamiento basado en benchmarks"""
        # Basado en benchmarks con Polars
        base_rate = 3000  # registros por segundo (estimaciÃ³n conservadora)
        
        estimated_seconds = total_rows / base_rate
        
        return {
            'estimated_seconds': estimated_seconds,
            'estimated_minutes': estimated_seconds / 60,
            'human_readable': (
                f"{estimated_seconds:.0f} segundos" if estimated_seconds < 60 else
                f"{estimated_seconds/60:.1f} minutos" if estimated_seconds < 3600 else
                f"{estimated_seconds/3600:.1f} horas"
            )
        }
    
    def generate_report(self, file_path: str) -> str:
        """Genera un reporte completo del anÃ¡lisis"""
        analysis = self.analyze_csv(file_path)
        
        if 'error' in analysis:
            return f"âŒ Error analizando {file_path}: {analysis['error']}"
        
        report = []
        report.append("=" * 60)
        report.append(f"ğŸ“Š REPORTE DE ANÃLISIS CSV")
        report.append("=" * 60)
        report.append(f"ğŸ“ Archivo: {os.path.basename(file_path)}")
        report.append(f"ğŸ“ TamaÃ±o: {analysis['file_size_mb']:.1f} MB")
        report.append(f"ğŸ“Š Dimensiones: {analysis['total_rows']:,} filas Ã— {analysis['total_cols']} columnas")
        report.append(f"â±ï¸ Tiempo de anÃ¡lisis: {analysis['analysis_time']:.2f}s")
        
        report.append("\nğŸ¯ ANÃLISIS DE PROPUESTAS (Columna B):")
        prop_analysis = analysis['propuesta_analysis']
        if 'error' not in prop_analysis:
            report.append(f"   âœ… Propuestas vÃ¡lidas encontradas: {prop_analysis['valid_propuestas_sample']}")
            report.append(f"   âŒ Celdas vacÃ­as: {prop_analysis['empty_propuestas_sample']}")
            report.append(f"   ğŸ“ Ejemplos: {', '.join(prop_analysis['sample_values'][:3])}")
        
        report.append("\nğŸ“ˆ CALIDAD DE DATOS:")
        quality = analysis['data_quality']
        report.append(f"   ğŸ¯ PuntuaciÃ³n: {quality['quality_score']:.1f}/100 ({quality['quality_level']})")
        report.append(f"   ğŸ“Š Celdas vacÃ­as: {quality['empty_cells_percentage']:.1f}%")
        
        report.append("\nğŸš€ RECOMENDACIONES DE RENDIMIENTO:")
        perf = analysis['performance_recommendation']
        report.append(f"   ğŸ”§ Estrategia: {perf['strategy'].title()}")
        report.append(f"   ğŸ’¾ Memoria estimada: {perf['memory_estimate']}")
        report.append(f"   ğŸ’¡ {perf['recommendation']}")
        
        report.append("\nâ±ï¸ ESTIMACIÃ“N DE PROCESAMIENTO:")
        estimate = analysis['processing_estimate']
        report.append(f"   ğŸ• Tiempo estimado: {estimate['human_readable']}")
        
        if analysis['format_issues']:
            report.append("\nâš ï¸ PROBLEMAS DETECTADOS:")
            for issue in analysis['format_issues']:
                report.append(f"   {issue}")
        
        report.append("\n" + "=" * 60)
        
        return "\n".join(report)

def main_monitor():
    """FunciÃ³n principal para ejecutar el monitor standalone"""
    monitor = SystemMonitor()
    
    try:
        monitor.start_monitoring(interval=2.0)
        
        # Mantener ejecutÃ¡ndose hasta Ctrl+C
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        monitor.stop_monitoring()
        print("\nğŸ‘‹ Monitor detenido por el usuario")

if __name__ == "__main__":
    # Si se ejecuta directamente, iniciar monitor
    main_monitor()